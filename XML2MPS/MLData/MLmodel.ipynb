{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+ab', 'a+b', 'ab+']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "MPSDataset_training = load_files(r\"/Users/nandini/Desktop/Finalfolder/FinalData/Training\") \n",
    "MPSDataset_test = load_files(r\"/Users/nandini/Desktop/Finalfolder/FinalData/Test\")\n",
    "print((MPSDataset_training.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print((MPSDataset_test.target_names))\n",
    "#print((MPSDataset_44_test.filenames))\n",
    "#mps_train = MPSDataset_44(subset='train')\n",
    "#print((MPSDataset_1_test.target_names))\n",
    "#print((MPSDataset_1.data.shape))\n",
    "#mps_train = MPSDataset_1(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 226)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(MPSDataset_training.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '123', '1234', '12345', '1234to', '123to', '12to', '13', '14', '15', '16', '17', '18', '19', '1to', '20', '2021', '21', '22', '23', '234', '23to', '24', '25', '26', '27', '28', '29', '2to', '30', '31', '32', '33', '34', '345', '34to', '35', '36', '37', '38', '39', '3to', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '4to', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '5to', '65', '657', '6578', '657to', '65to', '6to', '89', '890', '89to', '8to', '90', '98', '9to', 'added', 'arrow', 'ato', 'backspace', 'body', 'bto', 'child', 'command', 'concept', 'cond', 'ctrl', 'declarations', 'do', 'down', 'e1', 'e2', 'e_function', 'e_literal', 'enter', 'escape', 'exp', 'expression', 'file', 'for', 'from', 'function', 'handler', 'i_vardecl', 'if', 'in', 'info', 'ini', 'init', 'initi', 'initia', 'initial', 'initiato', 'initito', 'inito', 'initto', 'int', 'inti', 'intito', 'into', 'intto', 'is', 'ito', 'key', 'l_num', 'l_string', 'left', 'lhs', 'lit', 'lit_id', 'lit_idchanged', 'lit_numeric', 'lit_numericchanged', 'lit_stringchanged', 'literal', 'localizedfilenames', 'model', 'node', 'not', 'null', 'nullto', 'ops', 'parameters', 'parent', 'plugin', 'pr', 'present', 'pressed', 'pro', 'prof', 'profi', 'profit', 'profito', 'profto', 'property', 'proto', 'prto', 'pto', 'removed', 'rhs', 'right', 'root', 's_function', 'samplelog_0', 'samplelog_1', 'samplelog_10', 'samplelog_11', 'samplelog_12', 'samplelog_2', 'samplelog_3', 'samplelog_4', 'samplelog_5', 'samplelog_6', 'samplelog_7', 'samplelog_8', 'samplelog_9', 'saved', 'source', 'space', 'stat', 'statement', 'sto', 'su', 'sum', 'suto', 'the', 'this', 'to', 'tot', 'tota', 'total', 'totato', 'toto', 'totto', 'tto', 'txt', 'typed', 'up', 'var', 'vardecl', 'variabledeclaration', 'we', 'wel', 'welc', 'welco', 'welcom', 'welcome', 'welcomto', 'welcoto', 'welcto', 'welto', 'weto', 'wto']\n"
     ]
    }
   ],
   "source": [
    "#print(count_vect.get_feature_names())\n",
    "#print((X_train_counts[183,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 226)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf_1 = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(X_train_tfidf_1, MPSDataset_training.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "model_NB = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB())])\n",
    "model_NB = model_NB.fit(MPSDataset_training.data, MPSDataset_training.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 0 2 2 0 2 2 0 0 0 2 2 0 2 2 0 2 0 2 2 0 2 2 2 2 2 2 2 2 2 0\n",
      " 2 2 0 2 2 2 2 2 2 2 0 0 2 2 0 0 2 2 2 2 0 2 2 0 2 0 0 2 2 2 0 2 2 2 0 0 0\n",
      " 2 0 0 0 2 2 2 2 2 0 2 2 2 2 0 2 2 0 0 0 2 2 2 2 0 0 2 0 0 0 2 0 0 2 2 2 2\n",
      " 0 2 0 2 0 2 0 0 2 0 0 0 2 2 2 0 2 2 2 0 0 0 2 0 2 0 0 2 0 0 2 0 2 2 0 2 2\n",
      " 2 2 2 0 2 2 2 2 2 2 2 0 2 0 2 2 0 2 0 0 2 2 2 0 0 0 0 2 2 0 2 2 0 2 0 2 2\n",
      " 2 0 0 0 2 0 0 2 2 2 2 0 2 2 0 2 2 0 0 2 0 2 2 2 2 0 2 2 2 0 0 0 2 2 2 0 0\n",
      " 0 2 2 2 2 2 2 0 2 0 2 2 2 0 2 2 2 2 0 2 2 0 2 2 2 2 2 2 2 0 2 2 2 0 0 2 2\n",
      " 2 2 0 2 0 0 0 2 2 0 2 2 2 2 0 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7672727272727272"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted_1 = model_NB.predict(MPSDataset_test.data)\n",
    "print(predicted_1)\n",
    "np.mean(predicted_1 == MPSDataset_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 2 2 2 2 0 2 1 0 2 2 0 0 0 2 2 0 2 2 0 2 0 2 2 0 0 2 1 2 2 2 2 2 2 1\n",
      " 2 2 0 2 0 2 0 2 1 0 1 0 2 2 0 1 1 0 1 2 0 1 2 0 2 1 0 2 1 2 0 2 2 2 0 1 0\n",
      " 2 0 0 0 1 2 2 1 0 0 2 2 2 2 0 2 2 0 1 0 2 1 2 2 0 0 2 0 0 0 0 0 1 2 1 2 0\n",
      " 0 1 1 2 0 2 0 0 2 1 0 0 2 2 0 0 2 2 2 0 0 0 2 1 2 0 0 2 0 0 0 0 2 1 0 2 2\n",
      " 1 2 2 0 2 1 2 2 2 1 2 0 2 0 2 2 0 1 0 0 0 2 2 0 0 0 0 2 1 0 2 1 0 2 0 1 2\n",
      " 2 0 0 0 2 1 1 2 2 2 2 0 2 2 0 1 1 0 0 2 0 0 1 2 2 0 1 1 2 0 0 1 0 2 2 1 0\n",
      " 0 2 1 2 2 2 2 0 2 1 2 2 2 0 2 1 2 1 0 2 2 0 0 2 2 0 2 2 2 1 1 2 0 0 0 2 2\n",
      " 2 2 0 2 0 0 0 2 2 0 2 2 2 1 0 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9963636363636363"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model_svm = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None))])\n",
    "model_svm = model_svm.fit(MPSDataset_training.data, MPSDataset_training.target)\n",
    "predicted_svm = model_svm.predict(MPSDataset_test.data)\n",
    "print(predicted_svm)\n",
    "np.mean(predicted_svm == MPSDataset_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101,   0,   0],\n",
       "       [  0,  47,   1],\n",
       "       [  0,   0, 126]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(MPSDataset_test.target, predicted_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Folder']\n"
     ]
    }
   ],
   "source": [
    "Daily_Dataset = load_files(r\"/Users/nandini/Desktop/Finalfolder/Example_daily_log\")\n",
    "print((Daily_Dataset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 1 2 2 0 2 1 0 2 2 0 2 2 2 0 1 0 1 0 0 2 2 0 2 1 0 0 1 0 2 0 0 2 1 1\n",
      " 0 0 2 2 1 2 0 0 2 0 0 2 0 0 1 0 2 2 1 0 2 0 0 0 2 2 0 1 2 2 1 0 0 2 1 0 0\n",
      " 0 0 1 0 0 0 2 2 0 1 2 2 2 1 2 1 1 0 2 0 1 0 2 1 2 1 2 2 0 0 0 0 0 0 2 0 2\n",
      " 0 2 0 0 0 0 1 0 0 0 2 1 1 2 2 0 2 2 0 0 2 2 2 2 0 0 2 2 1 2 1 2 0 0 1 2 0\n",
      " 2 2 1 2 1 0 1 2 1 2 2 2 0 2 2 2 0 1 0 2 2 0 0 0 0 0 0 0 0 0 2 0 2 2 2 2 2\n",
      " 0 2 0 1 0 1 0 2 2 0 2 0 2 0 1 2 1 1 2 2 2 0 0 0 0 2 0 2 2 1 2 2 2 1 1 1 2\n",
      " 2 0 2 2 2 2 2 1 0 0 0 2 0 2 2 2 0 2 0 0 2 0 2 0 1 1 2 2 0 2 0 0 1 2 2 0 2\n",
      " 2 2 2 2 2 0 2 2 0 0 0 1 1 0 1 0 2 0 2 1 0 2 2 2 0 0 0 0 0 2 1 2 2 2 0 1 0\n",
      " 1 2 1 0 2 2 2 0 0 1 2 1 2 0 2 2 1 2 2 2 2 1 2 0 2 2 0 0 2 2 1 0 2 2 0 2 2\n",
      " 0 0 0 2 0 1 2 2 1 2 2 2 2 2 1 0 2 2 2 2 0 1 2 0 2 0 1 2 2 2 0 2 0 2 0 2 0\n",
      " 2 1 2 1 0 2 1 0 0 0 2 0 1 2 0 0 2 0 2 0 2 1 0 1 1 1 0 2 2 0 2 2 2 1 0 0 2\n",
      " 2 0 0 2 2 0 1 0 2 2 2 1 0 0 1 2 2 2 0 2 2 0 2 2 0 0 0 2 2 2 2 0 2 0 2 2 2\n",
      " 2 2 1 2 0 2 2 1 2 0 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 169, 2: 209, 1: 78})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Daily_DS_predicted_svm = model_svm.predict(Daily_Dataset.data)\n",
    "print(Daily_DS_predicted_svm)\n",
    "from collections import Counter\n",
    "Counter(Daily_DS_predicted_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['+ab', 169, 37.06140350877193, '%+%$a$$b$'], ['a+b', 78, 17.105263157894736, '$a$%+%$b$'], ['ab+', 209, 45.83333333333333, '$a$$b$%+%']]\n"
     ]
    }
   ],
   "source": [
    "w, h = 4, 3;\n",
    "Matrix = [[0 for x in range(w)] for y in range(h)] \n",
    "Matrix[0][0] = \"+ab\"\n",
    "Matrix[1][0] = \"a+b\"\n",
    "Matrix[2][0] = \"ab+\"\n",
    "Matrix[0][1] = Counter(Daily_DS_predicted_svm)[0]\n",
    "Matrix[1][1] = Counter(Daily_DS_predicted_svm)[1]\n",
    "Matrix[2][1] = Counter(Daily_DS_predicted_svm)[2]\n",
    "sum = Matrix[0][1] + Matrix[1][1] + Matrix[2][1]\n",
    "Matrix[0][2] = Counter(Daily_DS_predicted_svm)[0] /(sum) * 100\n",
    "Matrix[1][2] = Counter(Daily_DS_predicted_svm)[1] /(sum) * 100\n",
    "Matrix[2][2] = Counter(Daily_DS_predicted_svm)[2] /(sum) * 100\n",
    "Matrix[0][3] = \"%+%$a$$b$\"\n",
    "Matrix[1][3] = \"$a$%+%$b$\"\n",
    "Matrix[2][3] = \"$a$$b$%+%\"\n",
    "#Matrix[3][1] = sum\n",
    "#Matrix[3][2] = Matrix[0][2] + Matrix[1][2] + Matrix[2][2]\n",
    "print(Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a+b', 78, 17.105263157894736, '$a$%+%$b$'], ['+ab', 169, 37.06140350877193, '%+%$a$$b$'], ['ab+', 209, 45.83333333333333, '$a$$b$%+%']]\n"
     ]
    }
   ],
   "source": [
    "sort_list = sorted(Matrix,key=lambda x: x[1])\n",
    "print(sort_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "workbook = xlsxwriter.Workbook('Preference.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "worksheet.write('A1',sort_list[2][3])\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
